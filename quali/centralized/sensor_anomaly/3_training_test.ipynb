{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hfDTUh9zOd3"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from keras import Sequential, utils\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Set random state\n",
    "RANDOM_STATE = 42\n",
    "# Set random seed in Keras\n",
    "utils.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hbHrgoMTlso"
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def split_train_test(df, size, time_column):\n",
    "    # Build test DataFrame\n",
    "    test_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for i in np.sort(pd.unique(df['class'])): # For each class\n",
    "        temp_df = df[df['class'] == i] # Select only data from a class\n",
    "        # Obtain a percentage of data (end of DataFrame)\n",
    "        temp_df = temp_df.tail(round(len(temp_df) * size))\n",
    "        # Drop data obtained from the training DataFrame\n",
    "        df.drop(index=temp_df.index, inplace=True)\n",
    "        # Add data in test DataFrame\n",
    "        test_df = pd.concat([test_df, temp_df])\n",
    "\n",
    "    # Sort by time column and reset index\n",
    "    # df is training (and validating) DataFrame\n",
    "    df = df.sort_values(by=[time_column]).reset_index(drop=True)\n",
    "    test_df = test_df.sort_values(by=[time_column]).reset_index(drop=True)\n",
    "    # Return df and test_df excluding time column\n",
    "    return df.drop(columns=[time_column]), test_df.drop(columns=[time_column])\n",
    "\n",
    "\n",
    "\n",
    "def split_x_y(df, columns_to_drop):\n",
    "    # Columns to drop\n",
    "    df = df.drop(columns=columns_to_drop)   \n",
    "    # DataFrame X (features)\n",
    "    X = df.loc[:, df.columns != 'class']\n",
    "    y = df.loc[:, 'class'] # y (labels)\n",
    "    # Return DataFrame X and y\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def load_data(dataset_path, file_name, size=0.2):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(dataset_path + file_name)\n",
    "    # Split the data into 80% for training and 20% for test (default)\n",
    "    train_df, test_df = split_train_test(df, size, 'timestamp')\n",
    "    # Split train_df into X and y\n",
    "    X_train, y_train = split_x_y(train_df, [])\n",
    "    # Split train_df into X and y\n",
    "    X_test, y_test = split_x_y(test_df, [])\n",
    "    # GPS spoofing and jamming as a single category\n",
    "    y_test = y_test.replace(2, 1)\n",
    "    # Return train and test dataset\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def split_train_data(X_train, y_train):\n",
    "    train_data = X_train[y_train == 0] # Only normal samples\n",
    "    # Separate 90% of the indexes for validation\n",
    "    idx = int(train_data.shape[0] * 0.90)\n",
    "    val_data = train_data[idx:]  # Hold-out validation set for threshold calculation\n",
    "    train_data = train_data[:idx]  # Reduced x_train (with out val_data)\n",
    "    # Abnormal data from train set\n",
    "    # Used only for threshold estimation\n",
    "    abnormal_data = X_train[y_train != 0]\n",
    "    # Return training data after splitting\n",
    "    return train_data, val_data, abnormal_data\n",
    "\n",
    "\n",
    "\n",
    "def create_model(input_dim):\n",
    "    autoencoder = Sequential([ # Sequential autoencoder\n",
    "        Dense(units=32, activation='relu', input_dim=input_dim), # Encoder\n",
    "        Dense(units=16, activation='relu'),\n",
    "        Dense(units=8, activation='relu'),\n",
    "        Dense(units=4, activation='relu'),\n",
    "        Dense(units=8, activation='relu'), # Decoder\n",
    "        Dense(units=16, activation='relu'),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dense(units=input_dim, activation='sigmoid')\n",
    "    ])\n",
    "    # Autoencoder compile\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return autoencoder # Return autoencoder model\n",
    "\n",
    "\n",
    "\n",
    "def fit(autoencoder, train_data):\n",
    "    # Fit autoencoder\n",
    "    history = autoencoder.fit(train_data, train_data,\n",
    "                              epochs=100,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True,\n",
    "                              verbose=0)\n",
    "\n",
    "    # Return trained model and history loss\n",
    "    return autoencoder, history.history[\"loss\"][-1]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_reconstruction_loss(x, x_hat):\n",
    "    losses = np.mean(abs(x - x_hat), axis=1) # Mean Absolute Error (MAE)\n",
    "    return losses # Return losses\n",
    "\n",
    "\n",
    "\n",
    "def distance_calculation(losses, normal, abnormal):\n",
    "    # For each sample loss, calculate the minimun distance and set a label for test purpose\n",
    "    preds = np.zeros(len(losses)) # Create array for predicted values\n",
    "    for i, loss in enumerate(losses):\n",
    "        if abs(loss - normal) > abs(loss - abnormal):\n",
    "            preds[i] = 1 # Abnormal\n",
    "        else: preds[i] = 0 # Normal\n",
    "\n",
    "    return preds # Return predicted values\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_learning(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred) # Accuracy\n",
    "    recall = recall_score(y_true, y_pred) # Recall\n",
    "    precision = precision_score(y_true, y_pred) # Precision\n",
    "    f1 = f1_score(y_true, y_pred) # F1-score\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel() # Confusion matrix\n",
    "    missrate = fn / (fn + tp) # Miss rate\n",
    "    fallout = fp / (fp + tn) # Fall-out\n",
    "    auc = roc_auc_score(y_true, y_pred) # ROC AUC\n",
    "    # Return evaluation metrics\n",
    "    return accuracy, recall, precision, f1, missrate, fallout, auc\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, val_data, abnormal_data, X_test, y_test):\n",
    "    # Eval model on hold-out validation data\n",
    "    val_inference = model.predict(val_data, verbose=0)\n",
    "    # Eval model on abnormal data\n",
    "    abnormal_inference = model.predict(abnormal_data, verbose=0)\n",
    "    # Calculate reconstruction loss for validation and abnormal data\n",
    "    val_losses = calculate_reconstruction_loss(val_data, val_inference)\n",
    "    abnormal_losses = calculate_reconstruction_loss(abnormal_data, abnormal_inference)\n",
    "\n",
    "    # Threshold calculation\n",
    "    threshold_normal = np.mean(val_losses)\n",
    "    threshold_abnormal = np.mean(abnormal_losses)\n",
    "    # Show mean validation loss for normal and abnormal data (threshold)\n",
    "    print(\"Mean Validation Loss (Normal): {} | (Abnormal): {}\".format(\n",
    "        threshold_normal, threshold_abnormal))\n",
    "\n",
    "    # Test set evaluation\n",
    "    inference = model.predict(X_test, verbose=0)\n",
    "    losses = calculate_reconstruction_loss(X_test, inference)\n",
    "\n",
    "    # Threshold criteria\n",
    "    test_eval = distance_calculation(losses, threshold_normal, threshold_abnormal)\n",
    "    # Evaluate model learning with test data\n",
    "    accuracy, recall, precision, f1, missrate, fallout, auc = evaluate_learning(y_test, test_eval)\n",
    "    # Save metrics to a dictionary\n",
    "    metrics_dict = {\"accuracy\": round(accuracy, 5),\n",
    "                    \"recall\": round(recall, 5),\n",
    "                    \"precision\": round(precision, 5),\n",
    "                    \"f1_score\": round(f1, 5),\n",
    "                    \"missrate\": round(missrate, 5),\n",
    "                    \"fallout\": round(fallout, 5),\n",
    "                    \"auc\": round(auc, 5)}\n",
    "\n",
    "    # Show metrics on test data\n",
    "    print(\"\\nThreshold: {} \\nMetrics: {} \\n\\nMean Abnormal Loss: {} \\nMean Normal Loss: {}\".format(\n",
    "        threshold_normal, metrics_dict, np.mean(losses[y_test == 1]), np.mean(losses[y_test == 0])))\n",
    "    \n",
    "    # Return normal threshold and metrics dictionary\n",
    "    return threshold_normal, metrics_dict\n",
    "\n",
    "\n",
    "\n",
    "def show_plot_reconstrunction_error(model, test_data, threshold):\n",
    "    test_predictions = model.predict(test_data, verbose=0) # Predict test data\n",
    "    mse = np.mean(np.power(test_data - test_predictions, 2), axis=1) # Calculate Mean Squared Error (MSE) on test data\n",
    "    error_df = pd.DataFrame({'Reconstruction_error': mse}) # Build error DataFrame\n",
    "                            \n",
    "    fig, ax = plt.subplots(figsize=(12, 8)) # Plot settings\n",
    "    plt.rcParams.update({'font.size': 14}) # Font size\n",
    "    ax.plot(error_df.index, error_df.Reconstruction_error, marker='o', ms=3.5, linestyle='')\n",
    "    ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "    ax.legend()\n",
    "    plt.ylabel(\"Reconstruction Error\", fontsize=16)\n",
    "    plt.xlabel(\"Data Index\", fontsize=16)\n",
    "    plt.show()\n",
    "    # Return error DataFrame\n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXmypGgkcOx6"
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = '/home/leandro/remy-project/centralized/datasets/UAVGPSAttacks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1gAkCn1ZoCK"
   },
   "outputs": [],
   "source": [
    "# Autoencoder (AE)\n",
    "\n",
    "# Load datasets\n",
    "X_train, y_train, X_test, y_test = load_data(dataset_path, 'data_norm.csv')\n",
    "# Training data after splitting\n",
    "train_data, val_data, abnormal_data = split_train_data(X_train, y_train)\n",
    "\n",
    "input_dim = train_data.shape[1] # Number of predictor variables\n",
    "# Create autoencoder model\n",
    "model = create_model(input_dim)\n",
    "# Fit model\n",
    "model, loss_train = fit(model, train_data)\n",
    "\n",
    "# Normal threshold and metrics dictionary for GPS spoofing detection\n",
    "threshold_normal, metrics_dict = evaluate(model, val_data, abnormal_data, X_test, y_test)\n",
    "\n",
    "print('\\n\\nReconstrunction Error Plot for Normal Data:\\n')\n",
    "_ = show_plot_reconstrunction_error(model, X_test[y_test == 0], threshold=threshold_normal)\n",
    "print('\\n\\n\\nReconstrunction Error Plot for Abnormal Data:\\n')\n",
    "_ = show_plot_reconstrunction_error(model, X_test[y_test == 1], threshold=threshold_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2F8caQyhJyJ"
   },
   "outputs": [],
   "source": [
    "# One-Class SVM (OC SVM)\n",
    "model = OneClassSVM().fit(X_train[y_train == 0])\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "# Change anomalies values to make it consistent with the true values\n",
    "prediction = [1 if i==-1 else 0 for i in prediction]\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, prediction)\n",
    "\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, prediction, digits=5))\n",
    "print('\\nAUC: ' + str(round(auc, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_bViMzhikna"
   },
   "outputs": [],
   "source": [
    "# Local Outlier Factor (LOF)\n",
    "model = LocalOutlierFactor(n_jobs=-1, novelty=True).fit(X_train[y_train == 0].values)\n",
    "prediction = model.predict(X_test.values)\n",
    "\n",
    "# Change anomalies values to make it consistent with the true values\n",
    "prediction = [1 if i==-1 else 0 for i in prediction]\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, prediction)\n",
    "\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, prediction, digits=5))\n",
    "print('\\nAUC: ' + str(round(auc, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBV3kuW_GHx9"
   },
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "model = IsolationForest(n_jobs=-1, random_state=RANDOM_STATE).fit(X_train[y_train == 0].values)\n",
    "prediction = model.predict(X_test.values)\n",
    "\n",
    "# Change anomalies values to make it consistent with the true values\n",
    "prediction = [1 if i==-1 else 0 for i in prediction]\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, prediction)\n",
    "\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, prediction, digits=5))\n",
    "print('\\nAUC: ' + str(round(auc, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZn4DacMGmF7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSwT9vh/B4fxKkyKRVjzbb",
   "provenance": [
    {
     "file_id": "1K3FjSlC7rIJEss1NauCnZlPYzipBMYri",
     "timestamp": 1673432920944
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
