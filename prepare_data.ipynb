{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18352344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def split_train_test(df, size, time_column):\n",
    "    # Build test DataFrame\n",
    "    test_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for i in np.sort(pd.unique(df['class'])): # For each class\n",
    "        temp_df = df[df['class'] == i] # Select only data from a class\n",
    "        # Obtain a percentage of data (end of DataFrame)\n",
    "        temp_df = temp_df.tail(round(len(temp_df) * size))\n",
    "        # Drop data obtained from the training DataFrame\n",
    "        df.drop(index=temp_df.index, inplace=True)\n",
    "        # Add data in test DataFrame\n",
    "        test_df = pd.concat([test_df, temp_df])\n",
    "\n",
    "    # Sort by time column and reset index\n",
    "    # df is training (and validating) DataFrame\n",
    "    df = df.sort_values(by=[time_column]).reset_index(drop=True)\n",
    "    test_df = test_df.sort_values(by=[time_column]).reset_index(drop=True)\n",
    "    # Return df and test_df excluding time column\n",
    "    return df, test_df\n",
    "\n",
    "\n",
    "\n",
    "def split_clients_dataset(df, time_column, n_clients=4):\n",
    "    dfs = [] # List to save DataFrames for each client\n",
    "    classes_arr = np.sort(pd.unique(df['class'])) # Classes array\n",
    "\n",
    "    for class_num in classes_arr: # # For each class\n",
    "        temp_df = df[df['class'] == class_num] # # Select only data from a class\n",
    "\n",
    "        first_position = 0 # First position (row) of the DataFrame\n",
    "        # Calculating the approximate size of each DataFrame per client\n",
    "        approx_size = round(len(temp_df) / n_clients)\n",
    "        last_position = approx_size # Last position of the DataFrame\n",
    "        client_dfs = list() # Client DataFrames list\n",
    "\n",
    "        for client_num in range(n_clients): # For each client      \n",
    "            if client_num != n_clients - 1: # Not last client\n",
    "                client_dfs.append(temp_df.iloc[first_position:last_position,:])\n",
    "            else: # Last client\n",
    "                client_dfs.append(temp_df.iloc[first_position:,:])\n",
    "            \n",
    "            # Update first and last position\n",
    "            first_position += approx_size\n",
    "            last_position += approx_size\n",
    "        \n",
    "        # Append client_dfs in dfs\n",
    "        dfs.append(client_dfs)\n",
    "    \n",
    "    client_dfs = [] # Reset client DataFrames list\n",
    "    \n",
    "    for client_num in range(n_clients): # Build the DataFrame for each client\n",
    "        # Client DataFrame with all classes\n",
    "        client_df = pd.concat([dfs[class_num][client_num] for class_num in classes_arr])\n",
    "        client_dfs.append(client_df) # Append client_df in client_dfs\n",
    "    \n",
    "    return client_dfs # Return clients_dfs with all classes\n",
    "\n",
    "\n",
    "\n",
    "def save_client_datasets(train_df, test_df, time_column, n_clients=4):\n",
    "    for client_num in range(n_clients): # For each client\n",
    "        final_df = pd.DataFrame() # Create empty DataFrame\n",
    "        \n",
    "        for type_df in [train_df, test_df]: # For each type DataFrame\n",
    "            # Split clients DataFrame\n",
    "            temp_df = split_clients_dataset(type_df, time_column, n_clients=n_clients)[client_num]\n",
    "            final_df = pd.concat([final_df, temp_df]) # Concatenate training and test DataFrames\n",
    "            \n",
    "        final_df = final_df.sort_values(by=[time_column]).reset_index(drop=True) # Sort by time column\n",
    "        final_df.to_csv(f'{save_datapath}uav_data_{client_num + 1}.csv', index=False) # Save client dataset\n",
    "        \n",
    "    print('Clients datasets saved!') # Show that datasets have been saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to load the dataset\n",
    "load_datapath = '/home/leandro/remy-project/centralized/datasets/UAVGPSAttacks/'\n",
    "# Path to save the dataset\n",
    "save_datapath = '/home/leandro/remy-project/data/'\n",
    "\n",
    "# Split the data into 80% for training and 20% for test\n",
    "uav_df = pd.read_csv(load_datapath + 'data_norm.csv')\n",
    "train_df, test_df = split_train_test(uav_df, 0.2, 'timestamp')\n",
    "# Save client datasets\n",
    "save_client_datasets(train_df, test_df, 'timestamp', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb2f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
