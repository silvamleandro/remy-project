{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bAk0F5110bd"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Ignore warnings\n",
    "RANDOM_STATE = 42 # Random state default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu1rsk4dDVKb"
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def split_x_y(df):    \n",
    "    # DataFrame X (features)\n",
    "    X = df.loc[:, df.columns != 'class']\n",
    "    y = df.loc[:, 'class'] # y (labels)\n",
    "    # DataFrame X and y\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_figure=False, reports_path=None, file_name=None):\n",
    "    # Get confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Confusion matrix display\n",
    "    cm_p = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(10,10)) # Plot size\n",
    "    plt.rc('font', **{'size':14}) # Setting font size \n",
    "    cm_p.plot(ax=ax) # Confusion matrix plot show\n",
    "    \n",
    "    if save_figure == True: # Save figure\n",
    "        plt.savefig(reports_path + 'images/' + file_name + '.png')\n",
    "\n",
    "\n",
    "\n",
    "def classification_with_report(model, X, y, k, class_names, save_report=False, \n",
    "                               reports_path=None, file_name=None, verbose=True):    \n",
    "    # Lists\n",
    "    predicted_class = []\n",
    "    predicted_proba = []\n",
    "    original_class = []\n",
    "\n",
    "    # Stratified K-Folds cross-validator\n",
    "    skf = StratifiedKFold(k)\n",
    "    \n",
    "    start = time() # Time counting\n",
    "\n",
    "    # Train and validation the model for each 'k' fold in all the data\n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict with validation data\n",
    "        y_pred_proba = model.predict_proba(X_val)\n",
    "        # Add to list\n",
    "        predicted_proba.extend(y_pred_proba)\n",
    "\n",
    "        # Predict to generate classification report        \n",
    "        y_pred = model.predict(X_val)\n",
    "        predicted_class.extend(y_pred)\n",
    "        original_class.extend(y_val)\n",
    "\n",
    "    # Total time spent on training\n",
    "    total_time = time() - start\n",
    "    \n",
    "    roc_auc = roc_auc_score( # Calculate ROC AUC\n",
    "        original_class,\n",
    "        predicted_proba,\n",
    "        average=\"weighted\",\n",
    "        multi_class=\"ovr\")\n",
    "\n",
    "    if verbose == True: # Show results\n",
    "        # Results\n",
    "        print('\\t\\t\\tClassification Report\\n\\n')\n",
    "        print(classification_report(original_class, predicted_class, target_names=class_names, digits=5))\n",
    "        print('F1-Score: ' + str(round(f1_score(original_class, predicted_class, average='macro'), 5)))\n",
    "        print('AUC: ' + str(round(roc_auc, 5)))\n",
    "        print('Log Loss: ' + str(round(log_loss(original_class, predicted_proba), 5)))\n",
    "        print('Total Time: ' + str(round(total_time, 5)) + ' seconds')\n",
    "        print('Confusion Matrix:\\n')\n",
    "        plot_confusion_matrix(original_class, predicted_class, class_names)\n",
    "    \n",
    "    if save_report == True: # Save report\n",
    "        # file_name (without extension)\n",
    "        with open(reports_path + file_name + '.txt', 'a+') as f:\n",
    "            f.write(type(model).__name__ + '\\n ')\n",
    "            f.write(str(model))\n",
    "            f.write('\\n\\n\\n')\n",
    "            f.write('\\t\\t\\tClassification Report\\n\\n')\n",
    "            f.write(classification_report(original_class, predicted_class, target_names=class_names, digits=5))\n",
    "            f.write('\\n\\nF1-Score: ' + str(round((f1_score(original_class, predicted_class, average='macro')), 5)))\n",
    "            f.write('\\nAUC: ' + str(round((roc_auc), 5)))\n",
    "            f.write('\\nLog Loss: ' + str(round(log_loss(original_class, predicted_proba), 5)))\n",
    "            f.write('\\nTotal Time: ' + str(round(total_time, 5)) + ' seconds')\n",
    "            \n",
    "            plot_confusion_matrix(original_class, predicted_class, class_names,\n",
    "                                  save_figure=True, reports_path=reports_path, file_name=file_name)\n",
    "\n",
    "    return model # Return trained model\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial, X, y, k):\n",
    "    params = { # Hyperparameters that will be optimized\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_class': y.nunique(),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "    }\n",
    "\n",
    "    # Stratified K-Folds cross-validator\n",
    "    skf = StratifiedKFold(k)\n",
    "    scores = np.empty(5) # Save score of each fold\n",
    "\n",
    "    # Train and validation the model for each 'k' fold\n",
    "    for idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params) # Start model\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                  early_stopping_rounds=100,\n",
    "        )\n",
    "\n",
    "        # Predict the values based on the F1-score\n",
    "        preds = model.predict(X_val)\n",
    "        scores[idx] = f1_score(y_val, preds, average='macro')\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "\n",
    "def report_model(model, X, y, class_names):\n",
    "    # Predict to generate report     \n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Results\n",
    "    print('\\t\\t\\tClassification Report\\n\\n')\n",
    "    print(classification_report(y, y_pred, target_names=class_names, digits=5))\n",
    "    print('F1-Score: ' + str(round((f1_score(y, y_pred, average='macro')), 5)))\n",
    "    # Confusion matrix\n",
    "    print('\\nConfusion Matrix:\\n')\n",
    "    plot_confusion_matrix(y, y_pred, class_names)\n",
    "\n",
    "\n",
    "\n",
    "def save_object(obj, file_name):\n",
    "    with open(f'{file_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f) # Save object with .pkl extension\n",
    "\n",
    "\n",
    "        \n",
    "def load_object(file_name):\n",
    "    with open(f'{file_name}.pkl', 'rb') as f:\n",
    "        loaded_obj = pickle.load(f) # Load object saved as .pkl\n",
    "    \n",
    "    return loaded_obj # Return loaded object\n",
    "\n",
    "\n",
    "\n",
    "def lgb_plot_importance(booster, figsize, **kwargs):    \n",
    "    # Create figure with size defined\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    # Bar chart with the importance of features\n",
    "    return lgb.plot_importance(booster=booster, ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6w9l33148hff"
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "\n",
    "# Datasets path\n",
    "datasets_path = '/home/leandro/remy-project/centralized/datasets/WSN-DS/'\n",
    "# Reports path\n",
    "reports_path = '/home/leandro/remy-project/centralized/network_attacks/reports/'\n",
    "\n",
    "# Name of each class\n",
    "class_names = [\"Normal\", \"Grayhole\", \"Blackhole\", \"Flooding\"]\n",
    "\n",
    "# Load test dataset\n",
    "df_test = pd.read_csv(f'{datasets_path}test_data.csv')\n",
    "\n",
    "# Split test data into X and y\n",
    "X_test, y_test = split_x_y(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_type in ['none', 'ros', 'sm', 'k-sm', 'gans']:\n",
    "    # Load dataset, and split into X and y\n",
    "    X_train, y_train = split_x_y(pd.read_csv(f'{datasets_path}balanced/data_{dataset_type}.csv'))\n",
    "\n",
    "    # Compare algorithms\n",
    "    models = dict() # Create dictionary to save each model\n",
    "\n",
    "    # Decision Tree (default)\n",
    "    models['dt'] = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    # Random Forest (default)\n",
    "    models['rf'] = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "    # Gaussian Naive Bayes (default)\n",
    "    models['nb'] = GaussianNB()\n",
    "    # Multi-Layer Perceptron (default)\n",
    "    models['mlp'] = MLPClassifier(random_state=RANDOM_STATE)\n",
    "    # XGBoost (default)\n",
    "    models['xgb'] = xgb.XGBClassifier(verbosity=0, random_state=RANDOM_STATE)\n",
    "    # LightGBM (default)\n",
    "    models['lgb'] = lgb.LGBMClassifier(random_state=RANDOM_STATE, objective='multiclass')\n",
    "\n",
    "    for model_acronym in models.keys(): # Train and validate each dataset in each algorithm\n",
    "        plt.ioff() # Turn off plot show\n",
    "        _ = classification_with_report(models[model_acronym], X_train, y_train, 5, class_names,\n",
    "                                       save_report=True, reports_path=reports_path,\n",
    "                                       file_name=f'{dataset_type}-{model_acronym}', verbose=False)\n",
    "\n",
    "plt.ion() # Turn on plot show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7HjWwW7tPkV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use data balanced with GANs to optimize LightGBM\n",
    "X_train, y_train = split_x_y(pd.read_csv(f'{datasets_path}balanced/data_gans.csv'))\n",
    "\n",
    "# Optimize LightGBM hyperparameters\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"lightgbm\")\n",
    "func = lambda trial: objective(trial, X_train, y_train, 5)\n",
    "study.optimize(func, n_trials=10, n_jobs=-1)\n",
    "\n",
    "# Save the best parameters in a .pkl file\n",
    "save_object(study.best_params, 'best_paramns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best parameters\n",
    "best_params = load_object('best_paramns')\n",
    "# LightGBM (optimized)\n",
    "model = lgb.LGBMClassifier(**best_params)\n",
    "model = classification_with_report(model, X_train, y_train, 5, class_names,\n",
    "                                       save_report=True, reports_path=reports_path,\n",
    "                                       file_name='gans-lgb-o', verbose=False)\n",
    "# Save optimized LightGBM model\n",
    "save_object(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimized LightGBM model\n",
    "model = load_object('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the importance of each feature on the trained model\n",
    "lgb_plot_importance(model, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YuXBMDX5HYj"
   },
   "outputs": [],
   "source": [
    "# Test LightGBM with optimized hyperparameters on test data\n",
    "report_model(model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Step: Test Federated Learning with the Flower framework\n",
    "# https://flower.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPovo2T1FFBW3C7zc/9hq7+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
